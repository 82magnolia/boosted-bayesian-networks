{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"amazon_cells_labelled.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f2 = open(\"imdb_labelled.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f3 = open(\"yelp_labelled_fix_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f4 = open(\"train_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_list = [\"\" for i in range(1000)]\n",
    "for line,i in zip(f,range(1000)):\n",
    "    str_list[i] = re.sub('[.,]','',line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_list2 = [\"\" for i in range(1000)]\n",
    "for line,i in zip(f2,range(1000)):\n",
    "    str_list2[i] = re.sub('[.,]','',line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_list3 = [\"\" for i in range(11000)]\n",
    "for line,i in zip(f3,range(11000)):\n",
    "    str_list3[i] = re.sub('[.,]','',line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = 575\n",
    "str_list4 = [\"\" for i in range(length)]\n",
    "for line,i in zip(f4,range(length)):\n",
    "    str_list4[i] = re.sub('[.,]','',line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_super = str_list + str_list2 + str_list3 + str_list4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_list = str_list[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(str_super)):\n",
    "    str_super[i] = str_super[i].strip('\\t0\\n')\n",
    "    str_super[i] = str_super[i].strip('\\t1\\n')\n",
    "    str_super[i] = str_super[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(test_list)):\n",
    "    test_list[i] = test_list[i].strip('\\t0\\n')\n",
    "    test_list[i] = test_list[i].strip('\\t1\\n')\n",
    "    test_list[i] = test_list[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_list = [[] for i in range(1000)]\n",
    "for i in range(1000):\n",
    "    token_list[i] = word_tokenize(str_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_list2 = [[] for i in range(1000)]\n",
    "for i in range(1000):\n",
    "    token_list2[i] = word_tokenize(str_list2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_list3 = [[] for i in range(11000)]\n",
    "for i in range(11000):\n",
    "    token_list3[i] = word_tokenize(str_list3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_list4 = [[] for i in range(length)]\n",
    "for i in range(length):\n",
    "    token_list4[i] = word_tokenize(str_list4[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = [token_list[i][len(token_list[i]) - 1] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label2 = [token_list2[i][len(token_list2[i]) - 1] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label3 = [token_list3[i][len(token_list3[i]) - 1] for i in range(11000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label4 = [token_list4[i][- 1] for i in range(length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_label = label[:500] + label2 + label3 + label4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_label = label[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_label = ['1' if super_label[i] == '1' else '-1' for i in range(len(super_label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_label = ['1' if test_label[i] == '1' else '-1' for i in range(len(test_label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_data = [token_list[i][:len(token_list[i]) - 1] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_data = [[str_data[i][j].lower() for j in range(len(str_data[i]))] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_data2 = [token_list2[i][:len(token_list2[i]) - 1] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_data2 = [[str_data2[i][j].lower() for j in range(len(str_data2[i]))] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_data3 = [token_list3[i][:len(token_list3[i]) - 1] for i in range(11000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_data3 = [[str_data3[i][j].lower() for j in range(len(str_data3[i]))] for i in range(11000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_data4 = [token_list4[i][:len(token_list4[i]) - 1] for i in range(length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_data4 = [[str_data4[i][j].lower() for j in range(len(str_data4[i]))] for i in range(length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_super_data = str_data[:500] + str_data2 + str_data3 + str_data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_str_data = str_data[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_positive = [str_super_data[i] if super_label[i] == '1' else None for i in range(len(str_super_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_negative = [str_super_data[i] if super_label[i] == '-1' else None for i in range(len(str_super_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_pos = Counter([])\n",
    "for i in range(len(super_positive)):\n",
    "    super_pos += Counter(super_positive[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_neg = Counter([])\n",
    "for i in range(len(super_negative)):\n",
    "    super_neg += Counter(super_negative[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_pos = dict(super_pos)\n",
    "super_neg = dict(super_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_vocab = list(super_pos.keys())\n",
    "neg_vocab = list(super_neg.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_vocab = 35000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline(inptstr, phi_pos, phi_neg, phi_ypos, phi_yneg, num_vocab, pos_voc, neg_voc):\n",
    "    tok_list = word_tokenize(inptstr)\n",
    "    log_prob_pos = 0\n",
    "    log_prob_neg = 0\n",
    "    for word in tok_list:\n",
    "        if(word in pos_voc):\n",
    "            log_prob_pos += np.log(phi_pos[word])\n",
    "        else:\n",
    "            log_prob_pos += np.log(1/num_vocab)\n",
    "    for word in tok_list:\n",
    "        if(word in neg_voc):\n",
    "            log_prob_neg += np.log(phi_neg[word])\n",
    "        else:\n",
    "            log_prob_neg += np.log(1/num_vocab)\n",
    "    log_prob_pos += np.log(phi_ypos)\n",
    "    log_prob_neg += np.log(phi_yneg)\n",
    "    if(log_prob_pos >= log_prob_neg):\n",
    "        return '1'\n",
    "    else:\n",
    "        return '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_train(s_data, l_data, pos_voc, neg_voc, weight):\n",
    "    data_size = len(s_data)\n",
    "    tot_weight = sum([weight[i] for i in range(data_size)])\n",
    "    weight_pos = sum([weight[i] if l_data[i] == '1' else 0 for i in range(data_size)])\n",
    "    weight_neg = sum([weight[i] if l_data[i] == '-1' else 0 for i in range(data_size)])\n",
    "    phi_ypos = weight_pos/tot_weight\n",
    "    phi_yneg = weight_neg/tot_weight\n",
    "    phi_pos_num = {i:0 for i in pos_voc}\n",
    "    phi_neg_num = {i:0 for i in neg_voc}\n",
    "    for i in range(data_size):\n",
    "        str_size = len(s_data[i])\n",
    "        if(l_data[i] == '1'):\n",
    "            for j in range(str_size):\n",
    "                phi_pos_num[s_data[i][j]] += weight[i]\n",
    "        else:\n",
    "            for j in range(str_size):\n",
    "                phi_neg_num[s_data[i][j]] += weight[i]\n",
    "    phi_pos = {i:phi_pos_num[i]/weight_pos for i in pos_voc}\n",
    "    phi_neg = {i:phi_neg_num[i]/weight_neg for i in neg_voc}\n",
    "    return phi_pos, phi_neg, phi_ypos, phi_yneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error(s_raw, s_data, l_data, phi_pos, phi_neg, phi_ypos, phi_yneg, weight, num_vocab, pos_voc, neg_voc):\n",
    "    prediction = predict(s_raw, s_data, phi_pos, phi_neg, phi_ypos, phi_yneg, num_vocab, pos_voc, neg_voc)\n",
    "    data_size = len(s_data)\n",
    "    weighted_error = sum([weight[i] if prediction[i] != l_data[i] else 0 for i in range(data_size)])\n",
    "    return weighted_error,prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(s_raw, s_data, phi_pos, phi_neg, phi_ypos, phi_yneg, num_vocab, pos_voc, neg_voc):\n",
    "    data_size = len(s_data)\n",
    "    prediction = [baseline(s_raw[i], phi_pos, phi_neg, phi_ypos, phi_yneg, num_vocab, pos_voc, neg_voc) for i in range(data_size)]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boosting(s_raw, s_data, l_data, pos_voc, neg_voc, steps, num_vocab):\n",
    "    weight = [1/len(s_data) for i in range(len(s_data))]\n",
    "    beta = [0 for i in range(steps)]\n",
    "    phi_pos = [{} for i in range(steps)]\n",
    "    phi_neg = [{} for i in range(steps)]\n",
    "    phi_ypos = [0 for i in range(steps)]\n",
    "    phi_yneg = [0 for i in range(steps)]\n",
    "    for i in range(steps):\n",
    "        print('step',i)\n",
    "        phi_pos[i], phi_neg[i], phi_ypos[i], phi_yneg[i] = weight_train(s_data, l_data, pos_voc, neg_voc, weight)\n",
    "        weighted_error,prediction = error(s_raw, s_data,l_data,phi_pos[i],phi_neg[i],phi_ypos[i],phi_yneg[i], weight, num_vocab,pos_voc, neg_voc)\n",
    "        beta[i] = 0.5*np.log((1 - weighted_error)/weighted_error)\n",
    "        for j in range(len(s_data)):\n",
    "            weight[j] = weight[j]*np.exp(-beta[i]*float(l_data[j])*float(prediction[j]))\n",
    "    return beta, phi_pos, phi_neg, phi_ypos, phi_yneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boost_predict(inptstr, beta, phi_pos, phi_neg, phi_ypos, phi_yneg, num_vocab, pos_voc, neg_voc):\n",
    "    pred = 0\n",
    "    for i in range(len(beta)):\n",
    "        pred += beta[i]*float(baseline(inptstr, phi_pos[i], phi_neg[i], phi_ypos[i], phi_yneg[i], num_vocab, pos_voc, neg_voc))\n",
    "    if(pred >= 0):\n",
    "        return '1'\n",
    "    else:\n",
    "        return '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0\n",
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n",
      "step 5\n",
      "step 6\n",
      "step 7\n",
      "step 8\n",
      "step 9\n"
     ]
    }
   ],
   "source": [
    "beta, phi_pos, phi_neg, phi_ypos, phi_yneg = boosting(str_super, str_super_data, super_label, pos_vocab, neg_vocab,10, num_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9241301546391752\n",
      "0.9189292543021033\n",
      "0.9189292543021033\n",
      "0.9241301546391752\n",
      "0.9189292543021033\n",
      "0.0\n",
      "0.8155605670103093\n",
      "0.9069216061185469\n",
      "0.0\n",
      "0.998389175257732\n",
      "0.9196940726577438\n",
      "0.0\n",
      "0.9747100515463918\n",
      "0.935678776290631\n",
      "0.0\n",
      "0.8170103092783505\n",
      "0.9083747609942638\n",
      "0.0\n",
      "0.8356958762886598\n",
      "0.9190057361376673\n",
      "0.0\n",
      "0.9975837628865979\n",
      "0.9320076481835564\n",
      "0.0\n",
      "0.9758376288659794\n",
      "0.9380497131931166\n",
      "0.0\n",
      "0.8584085051546392\n",
      "0.92848948374761\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "test_len = 500\n",
    "train_len = len(super_label)\n",
    "count = [0 for i in range(10)]\n",
    "ncount = [0 for i in range(10)]\n",
    "neg_count = [0 for i in range(10)]\n",
    "for k in range(10):\n",
    "    for i in range(train_len):\n",
    "        if super_label[i] == boost_predict(str_super[i],beta[:k + 1], phi_pos[:k + 1], phi_neg[:k + 1], phi_ypos[:k + 1], phi_yneg[:k + 1], num_vocab, pos_vocab, neg_vocab):\n",
    "            count[k] += 1\n",
    "            if super_label[i] == '-1':\n",
    "                neg_count[k] += 1\n",
    "        if k >= 1:\n",
    "            continue\n",
    "        if super_label[i] == baseline(str_super[i],phi_pos[0],phi_neg[0],phi_ypos[0],phi_yneg[0], num_vocab,pos_vocab, neg_vocab):\n",
    "            ncount[k] += 1\n",
    "neg_len = super_label.count('-1')\n",
    "for k in range(10):\n",
    "    print(neg_count[k]/neg_len)\n",
    "    print(count[k]/train_len)\n",
    "    print(ncount[k]/train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8045977011494253\n",
      "0.738\n",
      "0.738\n",
      "0.8045977011494253\n",
      "0.738\n",
      "0.0\n",
      "0.5210727969348659\n",
      "0.69\n",
      "0.0\n",
      "0.842911877394636\n",
      "0.7\n",
      "0.0\n",
      "0.8237547892720306\n",
      "0.732\n",
      "0.0\n",
      "0.5210727969348659\n",
      "0.69\n",
      "0.0\n",
      "0.5172413793103449\n",
      "0.694\n",
      "0.0\n",
      "0.8275862068965517\n",
      "0.716\n",
      "0.0\n",
      "0.8237547892720306\n",
      "0.734\n",
      "0.0\n",
      "0.5287356321839081\n",
      "0.692\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "count = [0 for i in range(10)]\n",
    "ncount = [0 for i in range(10)]\n",
    "neg_count = [0 for i in range(10)]\n",
    "for k in range(10):\n",
    "    for i in range(test_len):\n",
    "        if test_label[i] == boost_predict(test_list[i],beta[:k + 1], phi_pos[:k + 1], phi_neg[:k + 1], phi_ypos[:k + 1], phi_yneg[:k + 1], num_vocab, pos_vocab, neg_vocab):\n",
    "            count[k] += 1\n",
    "            if test_label[i] == '-1':\n",
    "                neg_count[k] += 1\n",
    "        if k >= 1:\n",
    "            continue\n",
    "        if test_label[i] == baseline(test_list[i],phi_pos[0],phi_neg[0],phi_ypos[0],phi_yneg[0], num_vocab,pos_vocab, neg_vocab):\n",
    "            ncount[k] += 1\n",
    "neg_len = test_label.count('-1')\n",
    "for k in range(10):\n",
    "    print(neg_count[k]/neg_len)\n",
    "    print(count[k]/test_len)\n",
    "    print(ncount[k]/test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6208"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_label.count('-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-1'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_predict(\"\", beta, phi_pos, phi_neg, phi_ypos, phi_yneg, num_vocab, pos_vocab, neg_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baseline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-211ed3b84f8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbaseline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fuck\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi_pos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi_neg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi_ypos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi_yneg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'baseline' is not defined"
     ]
    }
   ],
   "source": [
    "baseline(\"fuck\", phi_pos[0], phi_neg[0], phi_ypos[0], phi_yneg[0], num_vocab, pos_vocab, neg_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "1.20781247091\n",
      "-1\n",
      "1.11577524526\n",
      "-1\n",
      "1.09027257771\n",
      "-1\n",
      "1.33785112918\n",
      "-1\n",
      "0.973972541647\n",
      "1\n",
      "1.37524715268\n",
      "1\n",
      "0.955980953122\n",
      "-1\n",
      "1.50900258262\n",
      "-1\n",
      "1.0273989497\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(baseline(\"\", phi_pos[i], phi_neg[i], phi_ypos[i], phi_yneg[i], num_vocab, pos_vocab, neg_vocab))\n",
    "    print(beta[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threshold(value): ##return true by probability of value\n",
    "    rnd = np.random.rand()\n",
    "    if rnd < value:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gibbs_sample(phi_pos, phi_neg, phi_ypos, phi_yneg, pos_voc, neg_voc, num_sample):\n",
    "    for smp in range(num_sample):\n",
    "        if(threshold(phi_ypos)):\n",
    "            print(\"positive:\")\n",
    "            for i in range(len(pos_voc)):\n",
    "                if(threshold(phi_pos[pos_voc[i]])):\n",
    "                    print(pos_voc[i],end = ' ')\n",
    "            print()\n",
    "        else:\n",
    "            print(\"negative:\")\n",
    "            for i in range(len(neg_voc)):\n",
    "                if(threshold(phi_neg[neg_voc[i]])):\n",
    "                    print(neg_voc[i],end = ' ')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative:\n",
      "the i my and that their sitting movie video cute indie seldom \n",
      "positive:\n",
      "for if this with all feels more your anything among situations scary karmen juice lump \n",
      "negative:\n",
      "it be that just nothing core making affair \n",
      "positive:\n",
      "you very to one it say of on they editing hope such reserving blush \n",
      "negative:\n",
      "to the a of that on bad best restaurants hickenlooper war generating pays \n",
      "positive:\n",
      "is this very never still hardly your girl material another hoot protagonist cheeks \n",
      "negative:\n",
      "for in might pay \n",
      "positive:\n",
      "you to with that clear not too but world mention winter \n",
      "positive:\n",
      "the is you have and quality a far it way film fact summary exceptional natural soon filmmakers \n",
      "positive:\n",
      "is you are and to a that say as its but go big much surprising deceitful \n",
      "positive:\n",
      "is and a best does into more ; important characters uneasily nerve barry \n",
      "positive:\n",
      "the and when has a light high actors fair once comics makers precision wang \n",
      "positive:\n",
      "the is you a it like know being enjoys cinderella \n",
      "positive:\n",
      "'s as about because be movies style public somewhere vastly \n",
      "positive:\n",
      "the far 's never n't know here movie makes hanging \n",
      "positive:\n",
      "i it two but she cinematic supremely chiefly \n",
      "positive:\n",
      "and with not know what book leaves career hey storytelling \n",
      "positive:\n",
      "the any a as work black fairly provocative strangely tales \n",
      "positive:\n",
      "the and a that gets `` strong heart-wrenching occur finishes \n",
      "positive:\n",
      "if to a with my it more film such sets smooth means \n",
      "positive:\n",
      "the everyone an film artist interesting by comedy sincere inexpensive derivative there's plympton \n",
      "positive:\n",
      "a that of in more but do film shows whimsy \n",
      "positive:\n",
      "the he a it of because writing vivid effects shocking video 're captures food roll \n",
      "positive:\n",
      "for the ! i up n't lovely gives keep superior \n",
      "positive:\n",
      "the was give movie world less adventure ability deliver 're half-hour required die-hard overflows \n",
      "positive:\n",
      "for the and weight solid film drive sophisticated \n",
      "positive:\n",
      "for the and a really more n't let stick spy tell once equally \n",
      "positive:\n",
      "for the is and i as how 'd delivery acting leaves proceedings \n",
      "positive:\n",
      "a with it no because but an off romance \n",
      "positive:\n",
      "the this and all end cast story gives 10/10 travel \n",
      "positive:\n",
      "is you this i love time wife did stories providing australia winsome thank \n",
      "positive:\n",
      "for a that like well of all in enough manages notable intelligent business allen \n",
      "positive:\n",
      "the this to a of instead in performance went culture slice filmmakers guilty \n",
      "negative:\n",
      "to in the us and n't this was cell happy movie making jagger quest \n",
      "positive:\n",
      "and a i 's black its worth ca memory vaudeville \n",
      "positive:\n",
      "is was never of but many before film much ca uses ] \n",
      "positive:\n",
      "good is and a with of everyone did sharp 'd -- although heart \n",
      "negative:\n",
      "in the a this its will those drama steak become \n",
      "positive:\n",
      "the is to a my it that 's ) fast be films ca period wedding twists there's \n",
      "negative:\n",
      "way it if how on few good an really otherwise ice simplistic remained \n",
      "positive:\n",
      "the is first few what happen latest ] men benefit \n",
      "positive:\n",
      "for the a my in films america behind simone responsibility \n",
      "positive:\n",
      "the was a as were than long feel wait certain formula \n",
      "positive:\n",
      "for the can but there truly become gay \n",
      "negative:\n",
      "for it and at can about hours has watch drag drive tried gags spurts \n",
      "positive:\n",
      "and about on delivery movie film characters movies taking comedies live \n",
      "positive:\n",
      "you and to that best ( but only got movie delivers having bit week \n",
      "positive:\n",
      "was when i it how suggests [ there's \n",
      "positive:\n",
      "that 's like even them am either movie minutes effects may accurately \n",
      "negative:\n",
      "is here of that this other back 'll pretty movies american john britney \n",
      "positive:\n",
      "the is have ! was a i 's make could an under often plot affair \n",
      "positive:\n",
      "this and to i make ever enough movie her hollywood enterprise \n",
      "negative:\n",
      "so for the i if and but full point our terribly proves \n",
      "positive:\n",
      "a in n't while real delivers film off twice accept \n",
      "positive:\n",
      "for and to a its life -- drama forget leaving oes plotting \n",
      "positive:\n",
      "and a i 's people line become amusing bad iced \n",
      "positive:\n",
      "the it that of on n't hair take film de audience \n",
      "positive:\n",
      "the is very to 's all not just there things fairly franklin \n",
      "positive:\n",
      "the going to one with like about ) or here long 10 much manage cherish \n",
      "positive:\n",
      "for the me in know an wo film by sort cuts spectacle winter \n",
      "positive:\n",
      "best but at merely pacino \n",
      "positive:\n",
      "the is and one it thing something entertaining charisma tickets \n",
      "positive:\n",
      "the ! to of again be at see much \n",
      "positive:\n",
      "the is this and a i with actually last knows society expand \n",
      "positive:\n",
      "for is as up everyone issues at level crafted process excitement tone urgently \n",
      "negative:\n",
      "there to the i than that again they ' saccharine predictability \n",
      "positive:\n",
      "for you and a not about time black its times -- makes flawed plotline \n",
      "positive:\n",
      "for you this and one it that more or n't makes sit awkward \n",
      "negative:\n",
      "i a that with series down its waiting story capable \n",
      "positive:\n",
      "and so no chase ideas stylistic kaputschnik ecks \n",
      "positive:\n",
      "the and any a that here what pure watching remarkable lunch stone surf \n",
      "positive:\n",
      "excellent the and to a i all will worth film sat tv -- moments historical deft \n",
      "positive:\n",
      "for the a with it 's like - what impossible there's \n",
      "positive:\n",
      "the and 's these more n't then note passion comedy known romantic unseen earmarks \n",
      "positive:\n",
      "a owned been will there amount hollywood incarnated \n",
      "negative:\n",
      "the i a and at was only after noses nair \n",
      "negative:\n",
      "to the a if that on like better movies him impossible acted wondering \n",
      "positive:\n",
      "is and very a of stuff be get \n",
      "positive:\n",
      "the and to extended a it of these in more also but voice some be scene movies script cant cut mainstream \n",
      "positive:\n",
      "great the though a it playful humor associated \n",
      "positive:\n",
      "the very of made does - in than which something things desperately veins \n",
      "positive:\n",
      "the is and a my in face film ? area hit-or-miss depth \n",
      "negative:\n",
      "is the that make his \n",
      "positive:\n",
      "the a it like time again many movie film dangerous comedy summer above-average obnoxious \n",
      "positive:\n",
      "if that me but movie watching detailing rest intelligent e \n",
      "positive:\n",
      "the this to one with now best n't be drama de sequel preachy \n",
      "positive:\n",
      "for the if to a say most be what something remains there's \n",
      "positive:\n",
      "the even no - will mess life his cinema utterly may warm flair monte \n",
      "positive:\n",
      "for and my into in less stirring witherspoon outrageous \n",
      "positive:\n",
      "the is and it now of an worthy road moviemaking alone \n",
      "positive:\n",
      "you and just home its do there `` life here director \n",
      "positive:\n",
      "the have ! in gets but strip deliver rhythm ensemble sign fool statement \n",
      "positive:\n",
      "good the is that even in more \n",
      "positive:\n",
      "it of feature family england there's stepmother \n",
      "positive:\n",
      "! and a it of they also n't movie film character poetry deliver dog cantet flourishes 84 escapes \n",
      "positive:\n",
      "is you a in an off vegas ensemble uniformly paulette grandparents tryna \n",
      "positive:\n",
      "the to a made instead in its here those movie at her become yourself exists ramsay king columbine contrasting \n",
      "positive:\n",
      "the and to it as of last display thought obviously girl bad jay vehicle \n",
      "negative:\n",
      "to the i my how far \n",
      "positive:\n",
      "is have one who time ; words such come finding \n"
     ]
    }
   ],
   "source": [
    "gibbs_sample(phi_pos[9],phi_neg[9],phi_ypos[9],phi_yneg[9],pos_vocab, neg_vocab, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_data = pd.read_table(\"train.tsv\", header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_data = np.array(n_data).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_data = [\"\" for i in range(8544)]\n",
    "count = 0\n",
    "for j in range(8544): \n",
    "    for i in range(count,len(n_data)):\n",
    "        if(n_data[i][1] == j + 1):\n",
    "            ref_data[j] = n_data[i][-2]\n",
    "            count = i + 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_label = [0 for i in range(8544)]\n",
    "count = 0\n",
    "for j in range(8544): \n",
    "    for i in range(count,len(n_data)):\n",
    "        if(n_data[i][1] == j + 1):\n",
    "            ref_label[j] = n_data[i][-1]\n",
    "            count = i + 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_label = ['1' if ref_label[i] >= 2 else '-1' for i in range(8544)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_token_list = [[] for i in range(8544)]\n",
    "for i in range(8544):\n",
    "    ref_data[i] = re.sub('[.,]','',ref_data[i])\n",
    "    ref_token_list[i] = word_tokenize(ref_data[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
